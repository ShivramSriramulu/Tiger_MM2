--- a/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java
+++ b/connect/mirror/src/main/java/org/apache/kafka/connect/mirror/MirrorSourceTask.java
@@ -1,5 +1,15 @@
 package org.apache.kafka.connect.mirror;
 
+import java.time.Duration;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutionException;
+import org.apache.kafka.clients.admin.*;
+import org.apache.kafka.common.TopicPartition;
+import org.apache.kafka.common.Uuid;
+import org.apache.kafka.common.errors.OffsetOutOfRangeException;
+import org.apache.kafka.common.errors.UnknownTopicOrPartitionException;
+import org.apache.kafka.connect.errors.ConnectException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 public class MirrorSourceTask extends SourceTask {
@@ -20,6 +30,12 @@ public class MirrorSourceTask extends SourceTask {
     // existing fields ...
+    private static final Logger FT_LOG = LoggerFactory.getLogger("mm2.fault.tolerance");
+    private Admin sourceAdmin;
+    private final ConcurrentHashMap<String, Uuid> topicIds = new ConcurrentHashMap<>();
+    private boolean failOnTruncation = true;
+    private boolean autoRecoverOnReset = true;
+    private long topicResetRetryMs = 5000L;
@@
     @Override
     public void start(Map<String, String> props) {
         // existing start logic ...
+        // fault-tolerance toggles
+        this.failOnTruncation = Boolean.parseBoolean(props.getOrDefault("mirrorsource.fail.on.truncation", "true"));
+        this.autoRecoverOnReset = Boolean.parseBoolean(props.getOrDefault("mirrorsource.auto.recover.on.reset", "true"));
+        this.topicResetRetryMs = Long.parseLong(props.getOrDefault("mirrorsource.topic.reset.retry.ms", "5000"));
+
+        // Build AdminClient for source cluster (same configs as source consumer)
+        Map<String, Object> adminProps = new HashMap<>(consumerProps);
+        sourceAdmin = Admin.create(adminProps);
     }
@@
-    private List<SourceRecord> pollRecords(Duration timeout) {
-        ConsumerRecords<byte[], byte[]> records = consumer.poll(timeout);
-        // existing processing
-    }
+    private List<SourceRecord> pollRecords(Duration timeout) {
+        try {
+            ConsumerRecords<byte[], byte[]> records = consumer.poll(timeout);
+            handleTopicResetIfAny();
+            return convert(records);
+        } catch (OffsetOutOfRangeException oore) {
+            if (!failOnTruncation) throw oore;
+            // Fail-fast with precise diagnostics
+            Map<TopicPartition, Long> earliest = consumer.beginningOffsets(consumer.assignment());
+            String msg = "TRUNCATION_DETECTED: Source offsets are out of range (likely retention purge). " +
+                         "Earliest per partition=" + earliest + ", assignment=" + consumer.assignment();
+            FT_LOG.error(msg, oore);
+            throw new ConnectException(msg, oore);
+        } catch (UnknownTopicOrPartitionException utpe) {
+            if (!autoRecoverOnReset) throw utpe;
+            FT_LOG.warn("TOPIC_RESET_SUSPECTED: {}. Will retry metadata and resubscribe in {} ms.", utpe.getMessage(), topicResetRetryMs);
+            sleep(topicResetRetryMs);
+            handleTopicResetIfAny();
+            return Collections.emptyList();
+        }
+    }
+
+    private void handleTopicResetIfAny() {
+        if (!autoRecoverOnReset) return;
+        // Describe all topics currently subscribed
+        Set<String> topics = consumer.subscription();
+        if (topics.isEmpty()) return;
+        try {
+            DescribeTopicsResult res = sourceAdmin.describeTopics(topics);
+            Map<String, TopicDescription> desc = res.all().get();
+            for (Map.Entry<String, TopicDescription> e : desc.entrySet()) {
+                String t = e.getKey();
+                Uuid current = e.getValue().topicId();
+                Uuid previous = topicIds.putIfAbsent(t, current);
+                if (previous != null && !previous.equals(current)) {
+                    FT_LOG.warn("RESET_DETECTED: Topic {} recreated (oldId={} newId={}). Seeking to beginning.", t, previous, current);
+                    // Seek to beginning for all assigned partitions of this topic
+                    Set<TopicPartition> toSeek = consumer.assignment().stream()
+                        .filter(tp -> tp.topic().equals(t))
+                        .collect(Collectors.toSet());
+                    if (!toSeek.isEmpty()) consumer.seekToBeginning(toSeek);
+                }
+            }
+        } catch (InterruptedException ie) {
+            Thread.currentThread().interrupt();
+        } catch (ExecutionException ee) {
+            // If topic truly doesn't exist yet, we'll retry on next poll
+            FT_LOG.debug("Topic describe failed; will retry: {}", ee.getMessage());
+        }
+    }
+
+    private static void sleep(long ms) {
+        try { Thread.sleep(ms); } catch (InterruptedException ie) { Thread.currentThread().interrupt(); }
+    }
